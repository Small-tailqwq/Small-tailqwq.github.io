---
layout: post  
title: 伪分布式安装hadoop
categories: 笔记
tags: hadoop
author: 土狗
---


* content
{:toc}


> 三点鸡肋，困稿拉臭嗨






> 这是一篇记录，没有对文章格式进行修饰，有很多地方可能看着很吃力，以后有空再改改  
大部分内容为[此视频](https://www.bilibili.com/video/BV1Kf4y1z7Nw)中的内容。

## 不想过多赘述的地方  

镜像为linux上课用的镜像，自定义安装，安装之后配置网络静态ip，重命名设备名称为“hadoop10x”（101递增）。在windows环境的host文件中加入主机名与相对应的ip，方便后续Xshell链接。（这里直接用火绒打开host文件修改就完事了）

> 如果一开始安装的时候没有修改主机名，可以通过指令来改  

```
vi /etc/sysconfig/network
#修改第二行的HOSTNAME，wq后reboot
```

由于 centos6 的 yum 源已经失效，这里替换为阿里的镜像源：  
```
wget -O /etc/yum.repos.d/CentOS-Base.repo http://file.kangle.odata.cc/repo/Centos-6.repo
wget -O /etc/yum.repos.d/epel.repo http://file.kangle.odata.cc/repo/epel-6.repo
yum makecache
```

## 安装 JDK
去 Oracle 官网下载 JDK 的压缩包，然后用rz上传(yum install lrzsz)或者直接 Vmtools都行，然后`tar -xvzf jdk.tar.gz`解压，然后开始配置变量。  
> 这里讲一下，我是把 JDK 配置到了系统变量和用户变量里，Hadoop的话是单独的用户变量。  
然后就是无论是哪个变量，更改完成之后一定要记得 `source` 一下，不然的话变量不会生效。  

```  
vim /etc/profile
```
> 填入变量，其中 JAVA_HOME 路径自行修改
```
export JAVA_HOME=/usr/java/jdk1.8.0_291
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib
```

> source
```
source /etc/profile
```
*具体安装流程常考[此处](https://blog.csdn.net/qq_36089184/article/details/94463584)*


## ssh免密码登录

> A主机生成公钥 (`id_dsa`) ，将A公钥存入B主机的 `authorized_keys` 文件内，公钥核对完成即可登录，跳过密码

```shell
# 生成公钥
ssh-keygen -b 1024 -t rsa
# 配置免密登录
ssh-copy-id 从节点ip或名称 -y
ssh-copy-id hadoop102
ssh-copy-id hadoop103
# 途中可能会要求输入B主机的 root 密码，输入即可，后续不必再次输入。  
# 为 `authorized_keys` 文件添加权限，保证安全性  
chmod 600 authorized_keys
```

## 配置时间同步 
> 所有节点都要进行配置

```
# 查询当前时间
date
或者
clock
# 进入计划任务
crontab -e
# 每小时从这个ntp服务器获取时间
0 1 * * * /usr/sbin/ntpdate cn.pool.ntp.org
# 也可手动获取
/usr/sbin/ntpdate 192.168.1.1
(因为我的路由器固件开启了ntp功能，直接路由器上获取更方便)
```

## 上传、配置hadoop文件
解压后在 `hadoopX.X.X/etc/hadoop/` 下修改，具体文件修改内容参考ppt  
ppt中的`node01`自行替换自己的 master 名称，
```xml
core-site.xml
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://主机名:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <!--指定一个临时文件的存放位置-->
        <value>/root/hadoopdate</value>
    </property>
<!---->
hdfs-site.xml
    <property>
        <name>dfs.replication</name>
        <!--设置副本个数-->
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node01:50090</value>
    </property>
<!---->
mapred-site.xml.template
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
<!---->
yarn-site.xml
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop101</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
<!---->
slaves
    添加从机id or ip
    hadoop102
    hadoop103
```

## 将 master 文件发送至从节点

```
scp -r hadoop目录 从节点名称:~/
scp -r hadoop-2.6.5 hadoop102:~/
scp -r hadoop-2.6.5 hadoop103:~/
```

## 用户变量中添加 `HADOOP_HOME`
> 所有节点都要进行配置

```shell
vim .bash_profile
export JAVA_HOME=/usr/java/jdk1.8.0_291
export PATH=$JAVA_HOME/bin:$PATH
# 添加HADOOP_HOME指向hadoophome的绝对路径
export HADOOP_HOME=/root/hadoop-2.6.5
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
# 改完之后不要忘了 source 一下
source .bash_profile
```


以上，配置完成


# 启动hadoop集群  
格式化hadoop，在master上执行  
**这条命令只要执行一次，多次执行会出错**
```
hdfs namenode -format
```
启动hadoop  
```
# 一键启动
start-all.sh
# 分步启动
start-dfs.sh
start-yarn.sh
停止的话把 start 换成 stop 即可
```
还可以输入 `jps` 查询启动状态，正常的话会有
